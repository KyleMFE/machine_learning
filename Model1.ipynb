{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithms\n",
    "\n",
    "### Regression problem:\n",
    "* Ordinal regression: Data in rank ordered categories\n",
    "* Poisson regression: Predict event counts\n",
    "* Fast forest quantile regression: Predict a distribution\n",
    "* Bayesian Linear regression: Linear model, small data sets\n",
    "* Nerual network regression: Accurate, long training times\n",
    "* Decision Forest regression: Accurate, fast training times\n",
    "* Boosted Decision Tree regression: Accurate, fast training times, large memory footprint\n",
    "\n",
    "### Clustering\n",
    "K-means: unsupervised learning\n",
    "\n",
    "### Anomaly detection\n",
    "* PCA-Based Anomaly detection: fast training times\n",
    "* Two-class Classification: Under 100 features, aggressive boundary\n",
    "\n",
    "### Two-class classification\n",
    "* Two-class SVM: under 100 features, linear model\n",
    "*  Two-class averaged perceptron: fast training, linear model\n",
    "* Two-class Bayes point machine: fast training, linear model\n",
    "* Two-class decision forest: accurate, fast training\n",
    "* Two-class logistic regression: Fast training. linear model\n",
    "* Two-class boosted decision tree: Accurate, fast training, large memory footprint\n",
    "* Two-class decision jungle: Accurate, small memory footprint\n",
    "* Two-class locally deep SVM: under 100 features\n",
    "* Two-class neural network: Accurate, long training times\n",
    "\n",
    "### Multicalss classification\n",
    "* Logistic regression: fast training times, linear model\n",
    "* Neural network: accurate, long training times\n",
    "* Decision forest: accurate. fast training times\n",
    "* decision jungle:\n",
    "* one-v-all multiclass: depends on the two-class classifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine learning\n",
    "* supervised learning ( labeled data, inputs and outputs)\n",
    "* unsupervised learning (data without labels, find patterns or intrinsic structures in the data, somehow reduce dimensions)\n",
    "* semi supervised learning (a small amount of labeled data with a large amount of unlabeled data)\n",
    "* reinforcement learning (maximize the **reward function**)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Underfitting VS Overfitting\n",
    "* **underfitting** : performs poorly in both training data and test data (**excessively simple**)\n",
    "* **overfitting** : performs perfectly in training data but fail to predict well on new data\n",
    "* both of them lead to poor predictions on new data\n",
    "\n",
    "### Model validation strategy\n",
    "* **Hold-out validation**\n",
    "* **k-fold cross validation**\n",
    "* **Leave-one-out cross validation**\n",
    "\n",
    "#### Hold-out strategy\n",
    "**Split the data into 2 parts- a training set, test set**  \n",
    "**Note:**: It can have a **high variance**. The evaluation may depend heavily on which data points end up in the training set and which end up in the test set and thus the evaluation may be significantly different depending on how the division is made.  \n",
    "\n",
    "**A better approach: Split the data into a training(60%), cross validation(20%) and test set(20%)**  (for relatively small data set)  \n",
    "#### k-fold cross validation\n",
    "** the data set is divided into k equal size subsets, and the Hold-out is repeated k times. Each time, one of the k subsets is used as test set, and the other k-1 subsets are put together to form a training set. Then the average error across all k trails is computed**  \n",
    "Adv: less depend on how the data is divided  \n",
    "Dadv: time-consuming, computation expensive  \n",
    "\n",
    "#### Leave-one-out cross validation(LOOCV)\n",
    "extreme case of k-fold, when k=n (sample size)  \n",
    "\n",
    "** Large dataset: hold-out validation**  \n",
    "** Small dataset: cross validation: 10-fold cross validation is common**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation metrics\n",
    "\n",
    "### Classification model\n",
    "* Accuracy  \n",
    "\n",
    " * $Accuracy = \\frac{n_{correct}}{n_{total}}$  \n",
    " * ** not a good metric for Skewed datasets, say a dataset with 1% patients**\n",
    " * only good for symmtric data\n",
    "\n",
    "* Precision  \n",
    "\n",
    "* Recall\n",
    "* F score\n",
    "* ROC\n",
    "* AUC\n",
    "* Log loss  \n",
    "\n",
    "### Confusion matrix visually shows more details of the error\n",
    "|                           |Predicted value(+)|Predicted value(-)  |  \n",
    "|------------------|------------------------------------------|\n",
    "|Actual Value(+)  |TP(True positive)   | FN(false negative) |\n",
    "|Acutal Value(-)   |FP(False positive)  |TN(True negative) |\n",
    "\n",
    "**True positive**: we predicted\"+\", and the true class is \"+\"    \n",
    "**True negative**: we predicted\"-\" and the true class is \"-\"  \n",
    "**False positive**: we predicted \"+‚Äù and the true class is \"-\"  \n",
    "**False negative**: we predicted\"-\" and the true class is \"+\"\n",
    "\n",
    "$$Accurancy = \\frac{TP+TN}{TP+FN+FP+TN}$$\n",
    "  \n",
    "$$Prediction = \\frac{TP}{TP+FP}$$  \n",
    "  \n",
    "$$Recall = \\frac{TP}{TP+FN}$$  \n",
    "  \n",
    "**There is an inverse relationship between precision and recall: trade off**\n",
    "\n",
    "\n",
    "### F score\n",
    "**F  score combines precision and recall into one measure**  \n",
    "** select the algorithm with the highest F score**\n",
    "$$F_1 = 2\\frac{P*R}{P+R}$$\n",
    "\n",
    "### ROC Curve\n",
    "* **ROC shows how many correct positive classifications can be gained as you allow for more and more false positives**  \n",
    "* **The closer this curve is to the upper left corner, the better the classifier's performance is **  \n",
    "* Insensitive to class distribution datasets\n",
    "\n",
    "### AUC(area under the curve)\n",
    "**Higher AUC will be better**\n",
    "\n",
    "### Regression Model\n",
    "* MAE\n",
    "* MSE\n",
    "* RMSE\n",
    "* MAPE\n",
    "* $R^2$ adjusted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to address underfitting(High Bias)\n",
    "* Train a more complex model\n",
    " 1. To make the same algorithm more complex (polynominal terms, more depth in decision tree)\n",
    " 2. Change to a more complicated algorithm/model (to neural network, random forest)\n",
    "* Add more features as input\n",
    "* Adjust parameters/Hyperparameters search\n",
    "* Use ensemble learning-Boosting\n",
    "\n",
    "### How t fix high variance issue(Overfitting)\n",
    "**Overfitting often occurs when a model is too complex or when there is insufficient data**  \n",
    "* use more data\n",
    "* use **regularization**   \n",
    "L2 regularization  (RIDGE) **Result in plenty of relatively small ut nonzero parameters**\n",
    "$$||\\theta||_2 = \\sum_{i=1}^n \\theta_i^2$$  \n",
    "L1 regularization:  (LASSO)**Push certain weights to be exactly 0**\n",
    "$$||\\theta||_2 = \\sum_{i=1}^n |\\theta_i|$$\n",
    "* reduce number of features\n",
    "* change to less complex model.\n",
    "* Adjust parameters/hyperparameters search\n",
    "* use ensemble learning- Bagging & Random forest  \n",
    "\n",
    "**Note: If learning algorithm is suffering from high bias, getting more data will not help**\n",
    "\n",
    "### Tuning the Hyperparameter\n",
    "Examples:\n",
    "1. number of trees in a random forest\n",
    "2. learning rate of gradient descent\n",
    "3. Regularization  \n",
    "\n",
    "**Hyperparameter**\n",
    "* it is a iterative process\n",
    " 1. Grid search\n",
    " 2. Random search(**recommended**)\n",
    " 3. Bayesian Optimization\n",
    "*  it controls the model complexity\n",
    "* It controls the behavior of the training algorithm\n",
    "\n",
    "### Hyperparameter VS parameter\n",
    "**Hyperparameter are specified before the training algorithm starts and can't be optimized inside the training algorithm itself. \n",
    "They are external to the model**\n",
    "* Used in processes to help estimate model parameters\n",
    "*  Cannot be estimated from data\n",
    "* Often specified by the practitioner\n",
    "* Not change during a training job  \n",
    "\n",
    "** Parameters are the variables that learning algorithm uses to adjust to your data. They are internal to the data**\n",
    "* Required by the model when making predictions\n",
    "* They are estimated or learned from data\n",
    "* Not set manually by the practitioner\n",
    "* They change during a training job\n",
    "\n",
    "Hyperparameter examples:  \n",
    "**neural network:**\n",
    "* Learning rate\n",
    "* Number of layers\n",
    "* Number of hidden units\n",
    "* Type of unit\n",
    "* Mini-batch size\n",
    "\n",
    "**SVM**\n",
    "* C, Kernel, gamma\n",
    "\n",
    "**Lasso,Ridge Regression**\n",
    "* Regularization parameter\n",
    "\n",
    "** K-means**\n",
    "* Number of clusters\n",
    "\n",
    "Parameter examples  \n",
    "**Neural networks**\n",
    "* weight\n",
    "\n",
    "**Linear Regression**\n",
    "* W and b\n",
    "\n",
    "\n",
    "**Grid search tries the exhaustive searches for all the possible hyperparameter combinations, so it is a costly and time-consuming approach**  \n",
    "**Prefer random search to grid search especially when hyperparameter search space is large**  \n",
    "** Try random value, don't use a grid, Use a coarse to fine sampling scheme**  \n",
    "** say, it can be helpful to first search in coarse ranges(e.g. $10^{**}[-6,1]$, and then depending on where the best results are turning up, narrow the range**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
